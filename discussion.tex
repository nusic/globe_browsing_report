\chapter{Discussion}
In this chapter, the resulting implementation and design decisions made through out the research phase and development phase will be discussed along with the results presented in chapter \ref{chapter:results}.

\section{Chunked LOD}
The performance related results of the benchmarks presented in section \ref{section:benchmarking} are discussed below.

\subsection{Chunk Culling}
From Figure \ref{fig:topdown} and \ref{fig:interaction} it is noted that the chunk tree grows as the ground facing camera comes closer to the surface, but the number of rendered chunks remain relatively constant. 
This is the desired result of the frustum culling algorithm, which efficiently culls most of the chunk tree as the camera looks straight down towards the ground. 
In Figure \ref{fig:topdown} we can also see that the total globe rendering time does not only depend on the number of rendered chunks. 
Even though the render call done for each rendered chunk is quite heavy (including accessing texture data and setting uniforms on the GPU), other things such as chunk selection and performing culling (done for each leaf node) are operations that also affect the render time. 

In figure \ref{fig:cullingcomp}, the culling algorithms are evaluated and compared for a camera view looking at the horizon. 
Looking at the horizon means a much larger geographical area is visible to the camera compared to looking straight down towards the ground as in the case discussed above. 
This means that chunk culling algorithms can not be expected to increase the rendering performance as much as in the case above. 
However, it can be seen that by using both the culling approaches, the globe rendering time is reduced approximately by a factor 10. 
When comparing the two, we see that the frustum culling algorithm does a much better job reducing the number of rendered chunks than than horizon culling. 
This is intuitively explained by the fact that horizon culling can only cull chunks far away, where the selection algorithm prefers choosing a few big, low resolution chunks any way. 
The frustum culling algorithm, on the other hand, may cull chunks that are both far away and very close to the camera. 
However, there is no practical reason for not using both the algorithms in combination at any time. 
The overhead of running both algorithms is payed back in rendering time as seen in figure \ref{fig:cullingcomp}.

\subsection{Chunk Selection}
\label{section:chunkselection}
In order to efficiently render camera views including facing the horizon, parameter tuning and optimization should not focus on chunk culling. 

Instead, the selection algorithm need to be carefully considered. 
In figure \ref{fig:lodcomp}, the two implemented chunk selection algorithms are compared to each other for such a camera view. 
We see that the algorithm based on the projected area is significantly faster than the distance based approach. 
The explanation for this is found by looking at the figures \ref{fig:cullingdcam} and \ref{fig:cullingacam} showing the corresponding view for the distance based and projected area based algorithm respectively. 
The projected area based algorithm prioritizes high level of detail close to the camera to a larger extent than the distance based approach, which is also how the algorithm gains its performance. 
By looking at the closest rendered chunks however, we see that the same level of detail was selected for both algorithms. 
Considering the relatively low difference in the visual appearance, one conclusion is that the projected area based algorithm is an efficient way to select chunks for rendering, especially for camera views looking at the horizon. Visual penalties will mainly be apparent when high detail is desired at distances far from the camera. Such cases can be when tall mountains are visible near the horizon.

\subsection{Chunk Switching}
The mipmapped texture data within a single dataset does not have to be strictly down sampled versions of the original size. 
The dataset may be combined from multiple different data sources such as satellite imagery and aerial photographs. 
Thus, two adjacent mip levels within a map dataset may look very different from one another. This is one motivation for using level blending as a main approach for chunk switching.

As seen in the results of section \ref{section:res_switching}, the level blending removes the otherwise visible edges between chunks of different level. However, the penality for using level blending is not directly the increase in render time (which is insignificant) but rather the loss of image quality, as seen in table \ref{table:resultblending}. Enabling the level blending algorithm for this specific case reduces the JPG compressed version of the screenshot from 1,1 Mb to 0,7 Mb; that is a reduction of 37\%. In other words, using level blending can be seen as trade off between poorer texture resolution versus popping artifacts and visible edges. In the end it all boils down to a tradeoff in render time as the LOD scale factor can be increased to compensate the overall loss in quality for the rendered globe. The qualty per rendered chunk, however, is undoubtedly reduced notably.

As mentioned in section \ref{section:chunkselection}, the projected area based selection approach was concluded to be more efficient than the distance based. However, using the area based approach comes with the drawback of not being able to correctly perform distance based chunk switching using level blending on a per-fragment basis. The convenience of using a simple distance based chunk selection algorithm is that the exact same calculations can be used in a fragment shader to calculate the interpolation parameter for the different mip levels of the texture datasets. Calculating a correct interpolation parameter corresponding to the projected area based chunk selection algorithm is a harder problem, not considered in the scope of this thesis. Conceptually, one approach could be to use bilinear interpolation based on four blending control points in each corner of the chunk. These values, however, would inherently depend on the LOD level of neighboring chunks, which makes the problem non-trivial. 

\subsection{Inconsistent Globebrowsing Performance}
Using quad trees (chunk trees) is a simple approach for hierarchically dividing a region into smaller subregions. 
However, the way the chunk trees are structured may cause different geographical regions to correspond to different types of chunk tree structures. 
That is, two different chunks on the same chunk level can correspond to large differences in the total number of nodes in the chunk tree. 
As an example: if the camera is looking at a small region just north of the equator, the whole southern hemisphere can be efficiently culled. 
However, if the camera moves just a few meters south, the chunk tree needs to suddenly consider a lot more chunks than previously. 
This effect will cause the performance of the rendering system to be affected by location. 
This would explain the same number of chunk nodes in figure \ref{fig:topdowngraph1} for East America and New York. 

From Figure \ref{fig:interaction} we can see that the chunk tree grows as the camera views the horizon, as do the number of rendered chunks. When turning the camera 180 degrees, the chunk tree shrinks temporarily. This is explained by the fact that the chunk tree growth is limited by the available tile data. Rotating half a revolution causes a lot of previously unseen chunks to no longer be culled by the culling algorithms. The tree grows again as the map tiles for these chunks are being fetched. 

\section{Ellipsoids vs Spheres}
Representing globes as ellipsoids and not as spheres was a decision settled early in the development process. 
The accuracy that the ellipsoidal model gives is important to be able to show near Earth orbits and rocket launches where the space crafts need to be positioned accurately relative to the WGS84 reference frame which is used in the SPICE library. 
Other globes such as the planet Saturn has a clearly visible ellipsoidal shape due to its angular momentum. This can now be shown in OpenSpace by configuring the planet to have the correct radii.

\section{Tesselation and Projection}
The choice of using geographic tessellation for the ellipsoid was a direct result of using equirectangular geodetic map projections. 
The equirectangular geodetic map projection is very common for many public map datasets and was therefore a given choice to be able to visualize a vast amount of data on the globes surfaces.

The drawbacks with oversampling at the poles giving undesired visual artefacts was considered, but in the end prioritized down due to time restrictions. However, due to the fact that the issue of polar pinching was not handled explicitly, the resulting issue of performance drops close to the poles can be seen in section \ref{section:res_polarpinching}.

The most reasonable solution to the polar issues would be to use polar caps similar to Dimitrijevi\'{c} and Ran\v{c}i\'{c}'s solution \cite{dimi15}. Even though the LOD algorithm is different, the similarities in tessellation map projection would mean that the implementation would have similar characteristics. Polar caps will however not solve all problems related to poles in geographical grid tessellations. The first time the software wants to render chunks on a polar cap near the pole, it will still need to request all the same tiles that a it would using a standard geographical grid tessellation. If it later is able to cache all reprojected tiles, they will be faster to render next time they are requested. The requests together with the re-projections will make it slower to visualize tiles at the caps, this could be a big limitation for datasets that needs to be accessed fast such as temporal datasets used for animating textures. Many of the GIBS datasets however are available in both equirectangular format as well as polar stereographic (EPSG:3413) for the North Pole and antarctic polar stereographic (EPSG:3031) for the South Pole. Hence re-projection would not be needed if the polar caps are defined with stereographic projections. 

\section{Chunked LOD vs Ellipsoidal Clipmaps}
Both Ellipsoidal clipmaps and chunked LOD were thoroghly considered as the overall LOD algorithm to used. Both methods were implemented as proofs of concepts before deciding on using the chunked LOD approach.

The clipmap implementation was aborted as the chunked LOD was significantly more straight forward to implement and early on started yielding visible results. Moreover, having decided on using equirectangular tessellation and map projection, the ellipsoidal clipmap approach would completely depend on an working implementation of polar caps, which would have extended the implementation time further with the need of considering both re-projection and edges.

Even though geometry clipmaps would pose some very different rendering challenges than the chunked LOD approach, many components developed for the chunked LOD approach could be shared between the two approaches.
The commonly used components would include the entire texture data pipeline and layer structure along with all the geometric related calculations, the interaction mode and various helper classes. The main difference is the rendering pipeline even though it also has similarities; for example, using the model space and camera space vertex rendering schemes could be done for geometry clipmaps just as well as for chunk grids.

\section{Parallel Tile Requests}
\label{section:parallelrequests}
Requesting tiles from a given remote dataset could in theory be performed in parallel but GDAL puts some restrictions on open datasets. GDAL can internally request tiles in parallel when performing the RasterIO operation. However, GDAL does not guarantee thread safe reading within all its formats. Reading from one open dataset on several threads in parallel often results in corrupt tiles. If the parallelization is limited to be performed on separate overviews however, GDAL's data writing and caching would hopefully not lead to race conditions between threads since overviews are completely separated from each other. Another method to speed up GDAL requests could be to open several GDAL dataset per tile dataset. However this will lead to internal cache misses within GDAL that most likely results in even slower requests and unnecessary memory usage.

\section{High Resolution Local Patches}
The software was implemented to be able to handle highly detailed datasets down to 25 centimeters per pixel as shown in section \ref{section:localpatchesresult} rendering HiRISE patches. Using the combination of HiRISE patches, CTX patches and a global terrain model with textures, the detail level together with the vast scale of surrounding canyon walls resulted in a combined view as close as possible to the real landscapes of Mars.

As described under Appendix \ref{appendix:localpatches} however, reading local patches used to render in OpenSpace requires extensive amount of preprocessing. Another issue is that a very sparse dataset specified with a virtual dataset (described in Appendix \ref{appendix:localpatches}) currently poses on OpenSpace is that empty tiles outside of the defined region are still initialized which makes the software run slower. The preprocessing and the unnecessary initialization makes reading and rendering of local patches more of a proof of concept and will be left for further development as future work.